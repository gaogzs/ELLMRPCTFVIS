{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ecc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.utils import resample\n",
    "\n",
    "cur_dir = \"C:/Users/Shavius/Documents/Uni/Year 4/Project/ELLMRPCTFVIS/dev\"\n",
    "data_dir = os.path.join(cur_dir, \"data\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Inter Rater Agreement\n",
    "\n",
    "def calculate_human_krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2725ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_metric_correlations(human_scores, candidate_base, candidate_refined, n_bootsraps=1000, significance=0.05, rounding=3):\n",
    "    \n",
    "    if len(human_scores) == 0 or len(candidate_base) == 0 or len(candidate_refined) == 0:\n",
    "        raise ValueError(\"Input series must not be empty.\")\n",
    "    \n",
    "    if len(human_scores) != len(candidate_base) or len(human_scores) != len(candidate_refined):\n",
    "        raise ValueError(f\"Input series must have the same length.{len(human_scores)} != {len(candidate_base)}, {len(human_scores)} != {len(candidate_refined)}\")\n",
    "    \n",
    "    base_corr, _ = spearmanr(human_scores, candidate_base)\n",
    "    refined_corr, _ = spearmanr(human_scores, candidate_refined)\n",
    "    \n",
    "    n_obervations = len(human_scores)\n",
    "    data_pairs = np.column_stack((human_scores, candidate_base, candidate_refined))\n",
    "    \n",
    "    bootstrap_base_corrs = []\n",
    "    bootstrap_refined_corrs = []\n",
    "    \n",
    "    for i in range(n_bootsraps):\n",
    "        sample = resample(data_pairs, n_samples=n_obervations, replace=True)\n",
    "        \n",
    "        boot_base_corr, _ = spearmanr(sample[:, 0], sample[:, 1])\n",
    "        bootstrap_base_corrs.append(boot_base_corr)\n",
    "        \n",
    "        boot_refined_corr, _ = spearmanr(sample[:, 0], sample[:, 2])\n",
    "        bootstrap_refined_corrs.append(boot_refined_corr)\n",
    "    \n",
    "    ci_lower_base = np.percentile(bootstrap_base_corrs, 100 * significance / 2)\n",
    "    ci_upper_base = np.percentile(bootstrap_base_corrs, 100 * (1 - significance / 2))\n",
    "    \n",
    "    ci_lower_refined = np.percentile(bootstrap_refined_corrs, 100 * significance / 2)\n",
    "    ci_upper_refined = np.percentile(bootstrap_refined_corrs, 100 * (1 - significance / 2))\n",
    "    \n",
    "    base_corr = round(base_corr, rounding)\n",
    "    ci_lower_base = round(ci_lower_base, rounding)\n",
    "    ci_upper_base = round(ci_upper_base, rounding)\n",
    "    refined_corr = round(refined_corr, rounding)\n",
    "    ci_lower_refined = round(ci_lower_refined, rounding)\n",
    "    ci_upper_refined = round(ci_upper_refined, rounding)\n",
    "    \n",
    "    return base_corr, (ci_lower_base, ci_upper_base), refined_corr, (ci_lower_refined, ci_upper_refined)\n",
    "    \n",
    "def evaluate_model_result(model_name, prefix):\n",
    "    human_scores = pd.read_csv(os.path.join(data_dir, f\"{prefix}_annotations_average.csv\"), index_col=0)[\"consistency\"].values\n",
    "    base_scores = pd.read_csv(os.path.join(data_dir, f\"{prefix}_baseline_output_{model_name}.csv\"), index_col=0)[\"consistency\"].values\n",
    "    refined_scores = pd.read_csv(os.path.join(data_dir, f\"{prefix}_combined_output_{model_name}.csv\"), index_col=0)[\"consistency\"].values\n",
    "    \n",
    "    base_corr, (base_lower_ci, base_upper_ci), refined_corr, (refined_lower_ci, refined_upper_ci) = calculate_metric_correlations(human_scores, base_scores, refined_scores, significance=0.1)\n",
    "\n",
    "    print(f\"Base model correlation: {base_corr} ({base_lower_ci}-{base_upper_ci})\")\n",
    "    print(f\"Refined model correlation: {refined_corr} ({refined_lower_ci}-{refined_upper_ci})\")\n",
    "    return base_corr, refined_corr, (base_lower_ci, base_upper_ci), (refined_lower_ci, refined_upper_ci)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
